<!-- Observation 4: Nobody Knows What's Inside -->
{% include observations/observation-detail.html
    id="observation-4"
    number="04"
    title="Nobody Knows What's Inside"
    bg="bg-terminal-surface"
    problem="Stanford's Foundation Model Transparency Index (December 2025) scored major AI companies at just 41/100 on average—down 17 points from 2024. OpenAI dropped 14 points. Meta dropped 29. Both fell from 1st-2nd place in 2023 to 5th-6th in 2025. Only 30% of companies even responded to transparency requests (down from 74%). The lowest scorers? xAI and Midjourney at 14/100. This isn't secrecy for safety. It's secrecy for competitive advantage."
    quote="Transparency is a vital precondition for public accountability, scientific innovation, and effective governance."
    quote_source="<a href='https://arxiv.org/abs/2310.12941' target='_blank' class='text-terminal-green hover:underline'>The Foundation Model Transparency Index</a>"
    why_matters="We're building critical infrastructure on foundations we cannot examine. When AI makes decisions about hiring, lending, healthcare, and justice, 'trust us' isn't good enough. Science requires verification. Democracy requires transparency. Even 'open' models like Meta's score poorly—openness doesn't guarantee transparency."
    ohgod_solution="OHGOD!! What if you could see exactly how your AI works? What if every architecture choice, training dataset, and failure mode was documented? No black boxes. No 'trust us.' You train it yourself, so you know what's inside. The industry scores 41/100 on transparency, we can do better."
%}
