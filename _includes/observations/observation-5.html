<!-- Observation 5: The Intelligence of the Gaps -->
{% include observations/observation-detail.html
    id="observation-5"
    number="05"
    title="The Intelligence of the Gaps"
    bg="bg-terminal-bg"
    problem="Medieval scholars attributed the unexplained to God; we attribute impressive LLM outputs to 'intelligence.' But for transformers, we actually know a lot: induction heads drive in-context learning, FFN layers store facts as key-value memories, sparse autoencoders extract interpretable features, circuit tracing maps decision pathways. Hallucinations, sycophancy, memorization; these aren't mysterious emergent properties. They're statistical pattern-matching we should examine more."
    quote="Just as 'God of the gaps' shrinks as science advances, our definition of 'intelligence' keeps shifting. There's a running joke in AI: intelligence is whatever computers haven't done yet."
    quote_source="<a href='https://engineeringprompts.substack.com/p/ai-and-the-god-of-the-gaps' target='_blank' class='text-terminal-green hover:underline'>Marcel Salath√©, 'AI and the God of the Gaps' (2024)</a>"
    why_matters="72% of users trust AI for facts. 75% of those get misled. Hallucinations, sycophancy, memorization; these aren't mysteries. They're predictable outcomes we could fix with more experimenting."
    ohgod_solution="OHGOD!! What if 'intelligence' is just a label for what we haven't examined yet? Build small enough to train yourself, and you can call it what it actually is."
%}
